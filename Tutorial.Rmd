---
title: "Interaktives Lerntutorial Data Science"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(readxl)
library(tidyverse)
library(DT)
library(shiny)
library(plotly)
library(dplyr)
titanic <- read_xlsx("Titanic.xlsx")
```

## Datenbasis

### Der Datensatz

Der in unserem Tutorial verwendete Datensatz stammt von der Website [Kaggle](https://www.kaggle.com/) und enthält Informationen über die Passagiere der Titanic.
Der Datensatz ist weit verbreitet und wird oft für das Training von KI und Machine-Learning genutzt ([Titanic Dataset](https://www.kaggle.com/datasets/sakshisatre/titanic-dataset/data)).

Die Merkmale welche im Datensatz verwendet werden sind folgende:

* Klasse
* Überlebt (1=Ja, 0=Nein)
* Name
* Geschlecht
* Alter
* Anzahl der Geschwister und Ehepartner auf dem Schiff
* Anzahl der Eltern auf dem Schiff
* Ticketnummer
* Ticketpreis
* Kabinennummer
* Zustiegshafen (Kürzel)
* Nummer des Rettungsboots (wenn überlebt)
* ID-Der Leiche (wenn gestorben)
* Herkunft

Hier ein Ausschnitt aus der Tabelle:

```{r view head, echo = FALSE}
datatable(titanic, options = list(pageLength = 5, scrollX = TRUE))
```

### Hypothesen

Folgende Hypothesen haben wir aufgestellt und wollen diese im Verlauf dieses Tutorials Überprüfen:

* Die Wahrscheinlichkeit als Frau zu überleben ist höher, als als Mann.
* Die Wahrscheinlichkeit zu überleben steigt mit der Wertigkeit der gebuchten Klasse.
* Die Wahrscheinlichkeit zu überleben sinkt mit dem Anstieg des Alters.


## Datenaufbereitung


### Einlesen der Daten

Um die Daten aus einer Excel-Datei zu lesen, verwenden wir die 'readxl'-Bibliothek.
```{r readdata}
salary <- read_xlsx("Titanic.xlsx")
```
Für eine CSV-Datei würde der Befehl so lauten:<br>
*salary <- read_csv("Titanic.csv")*

Die Daten einer Erhebung werden in der Regel als **Rohdaten** oder **Urlisten** bezeichnet und wurden noch nicht bearbeitet.<br>
Bei einer **Vollerehebung** werden bei der Datenerhebung alle statistischen Einheiten einer Grundgesamtheit erfasst. 
Da dies in den meisten Fällen nicht möglich ist, erfolgt eine **Teilerhebung** in Form einer **Stichprobe**.<br>
Dies ist auch hier der Fall gewesen.


### Inkonsistenzen und Leerstellen beheben

Da Rohdaten häufig unvollständig, inkonsistent oder fehlerbehaftet sind, muss im ersten Schritt eine **Datenbereinigung** stattfinden. 
Hierbei werden die Daten vorverarbeitet und somit verändert, aufgefüllt oder auch gelöscht. <br>
Was in einem konkreten Fall sinnvoll ist, hängt vom Datentyp, der Anwendung und Fragestellung ab.<br>
Bekannte Beispiele für Dateninkonsistenzen sind Datumsangaben oder Länderbezeichnungen. Wo Datumsangaben bei unterschiedlichen Formaten mit Tools wie Excel oder R automatisch angepasst werden können, bedürfen Länderbezeichnungen oft manueller oder halbautomatische Lösungen.

Eine besondere Aufmerksamkeit gilt auch dem Umgang mit fehlenden Daten, die sowohl bei selbst erhobenen, als auch bei extern bezogenen Datenquellen auftreten können.<br>
Hierbei gibt es zwei gängige Methoden, fehlende Daten zu handhaben:

#### Ausschluss von Daten

Die einfachste Möglichkeit im Umgang mit fehlenden Daten ist der Ausschluss von Beobachtungen mit fehlenden Daten.
Dabei muss zuerst entschieden werden, welche Merkmale besonders wichtig für den Datensatz sind und welche nach möglichkeit keine **NULL-Werte** enthalten sollten.

Welche von den vorherigen genannten Merkmalen könnten in unserem Datensatz besonders relevant sein (auch im Hinblick auf unsere Hypothesen)?

```{r quiz1, echo=FALSE}
question("Bitte wähle alle Merkmale aus, welche du für notwendig hältst.",
         answer("Klasse", correct = TRUE, message = "Korrekt, das Merkmal 'Klasse' ist notwendig um die zweite Hypothese zu überprüfen."),
         answer("Überlebt", correct = TRUE, message = "Da sich der Datensatz und unsere Hypothesen alle um das Überleben drehen, ist das Merkmal 'überlebt' auch zwingend notwendig."),
         answer("Name", message = "* Name"),
         answer("Geschlecht", correct = TRUE, message = "Auch das 'Geschlecht' wird benötigt, da hiermit die erste Hypothese überprüft werden kann."),
         answer("Alter", correct = TRUE, message = "Letzten Endes benötigen wir noch das 'Alter', um die dritte Hypothese zu überprüfen."),
         answer("Anzahl der Geschwister und Ehepartner auf dem Schiff", message = "* Anzahl der Geschwister und Ehepartner auf dem Schiff"),
         answer("Anzahl der Eltern auf dem Schiff", message = "* Anzahl der Eltern auf dem Schiff"),
         answer("Ticketnummer", message = "* Ticketnummer"),
         answer("Ticketpreis", message = "* Ticketpreis"),
         answer("Kabinennummer", message = "* Kabinennummer"),
         answer("Zustiegshafen", message = "* Zustiegshafen"),
         answer("Nummer des Rettungsboots", message = "* Nummer des Rettungsboots"),
         answer("ID-Der Leiche", message = "* ID-Der Leiche"),
         answer("Herkunft", message = "* Herkunft"),
         type = "multiple",
         incorrect = "Folgende Merkmale sind nicht notwendig:"
         )
```
Da wir nun alle wichtigen Merkmale identifiziert haben, können wir uns darum kümmern, den Datensatz zu bereinigen.
Hierfür bereinigen wir erst alle Einträge, welche keine Angaben bei unseren wichtigen Mermalen enthalten.
Da der Datensatz von Natur aus keine NULL-Werte in den Spalten "überlebt", "Klasse" und "Geschlecht" enthält, müssen wir das nur noch für das Mermal "Alter" tun.

Hierfür legen wir als erstes eine neue Tabelle mit dem Namen "titanic_clean" an:<br>

```{r copy table}
titanic_clean <- titanic
```

Anschließend entfernen wir mit Hilfe einer Filter-Funktion alle Zeilen mit NULL-Werten beim "Alter":<br>

```{r delete missing}
titanic_clean <- titanic_clean %>%
  filter(!is.na(age))

datatable(titanic_clean, options = list(pageLength = 5, scrollX = TRUE))
```

Wie zu erkennen ist, hat die Tabelle nun einige Seiten weniger und es sind keine NULL-Werte mehr beim "Alter" vorhanden.
Als nächstes wollen wir noch alle unrealistischen Einträge entfernen. Hierfür beschränken wir uns wieder nur auf das "Alter", da dieses leicht einzuschätzen ist und die anderen wichtigen Merkmale keine fehlerhaften Werte enthalten.<br>
Versuchen Sie nun alle Einträge mit einem höheren "Alter" als 100 zu entfernen. Der korrekte Name der Spalte ist dabei "age".

```{r delete_unrealistic_age, exercise = TRUE, excercise.eval = FALSE}
titanic_clean2 <- titanic %>%
  filter(!is.na(age)) %>%
  filter()

datatable(titanic_clean2, options = list(pageLength = 5, scrollX = TRUE))
```

```{r delete_unrealistic_age-solution}
titanic_clean2 <- titanic %>%
  filter(!is.na(age)) %>%
  filter(age < 101)

datatable(titanic_clean2, options = list(pageLength = 5, scrollX = TRUE))
```
<br>
Wunderbar! Nun haben wir eine Tabelle, welche keine Fehlerhaften und unbrauchbaren Daten mehr enthält.<br>

#### Imputation

Die andere Methode ist es, fehlende Daten durch "sinnvolle" Daten zu ersetzen. Hierbei werden am einfachsten Lagemaße wie Mittelwert, Median oder Modus als "sinnvolle" Werte verwendet. Aufwendigere Verfahren arbeiten mit speziellen Schätzern, die beispielsweise Regressionsverfahren verwenden.
<br>
<br>
Für eine Zusammenfassung, wie die Datenaufbereitung in R funktioniert, kannst du dir dieses Video anschauen:<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/FcxiSwZcPvw?si=JeCbEg15XfJXCG5z" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Datenanalyse


### Mittelwert

### Median

### Varianz

### Standardabweichung

### Lineare Regression

### Überprüfung der Hypothesen

## Ergebnispräsentation

## Teaminfos

